{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**Changes to original notebook:**\n",
    "1. using \"benign_objects\" to denote objects that should not indicate the\n",
    "presence of cancer in a patch.\n",
    "  i. represented graphically with blue circles.\n",
    "\n",
    "2. using \"cancerous_objects\" to denote objects that should indicate the presence\n",
    "of cancer in a patch.\n",
    "  ii. represented graphically with red circles.\n",
    "\n",
    "3. changed the max and min diameter and # of objects to more closely matches the\n",
    "TMA dataset.\n",
    "\n",
    "4. altered code to accomodate 3D synthetic images (RGB).\n",
    "\n",
    "5. added visualization scripts from \"visualize densenet\" file"
   ],
   "metadata": {
    "id": "kpQmyVjwlKIK"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import random\n",
    "import tables\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "from snippets import print_bag\n",
    "\n",
    "seed = random.randrange(sys.maxsize) #get a random seed so that we can reproducibly do the cross validation setup\n",
    "random.seed(seed) # set the seed\n",
    "print(f\"random seed (note down for reproducibility): {seed}\")"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4QVuyhJ-4yr6",
    "outputId": "59d821fd-4376-4516-f284-f98c9cff7b46"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataname=\"MIL_32x32_100pos\"\n",
    "\n",
    "patch_size= 32 #size of the tiles to put into DB\n",
    "data_size=np.array([10000, 3000])\n",
    "\n",
    "num_slides = np.floor(data_size / 244).astype(int)\t# the expected ratio of slides to patches is 1:244. (4000^2 / 256^2) So the number of slides should be num_patches/244\n",
    "train_slide_ids = np.arange(num_slides[0])\n",
    "val_slide_ids = np.arange(num_slides[1])\n",
    "\n",
    "classes=[0,1] #what classes we expect to have in the data.\n",
    "percent_pos_per_slide=1.0\n",
    "\n",
    "max_benign_objects= 3\n",
    "max_cancerous_objects=1\n",
    "diameter_min=5\n",
    "diameter_max=10\n",
    "\n",
    "phases=[\"train\",\"val\"]"
   ],
   "outputs": [],
   "metadata": {
    "id": "KW_qUXkF5flJ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%cd data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "img_dtype = tables.UInt8Atom()  # dtype in which the images will be saved, this indicates that images will be saved as unsigned int 8 bit, i.e., [0,255]"
   ],
   "outputs": [],
   "metadata": {
    "id": "7TdE5uQ24zic"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib inline\n",
    "storage={} #holder for future pytables\n",
    "\n",
    "block_shape=np.array((patch_size,patch_size, 3)) #block shape specifies what we'll be saving into the pytable array, here we assume that masks are 1d and images are 3d\n",
    "\n",
    "filters=tables.Filters(complevel=6, complib='zlib') #we can also specify filters, such as compression, to improve storage speed\n",
    "\n",
    "\n",
    "for phase,nimgs in zip(phases,data_size): #now for each of the phases, we'll loop through the files\n",
    "\tprint(phase)\n",
    "\t\n",
    "\ttotals=np.zeros(2) # we can to keep counts of all the classes in for in particular training\n",
    "\n",
    "\thdf5_file = tables.open_file(f\"./{dataname}_{phase}.pytable\", mode='w') #open the respective pytable\n",
    "\n",
    "\n",
    "\tstorage[\"imgs\"]= hdf5_file.create_earray(hdf5_file.root, \"imgs\", img_dtype,  \n",
    "\t\t\t\t\t\t\t\t\t\t\tshape=np.append([0],block_shape), \n",
    "\t\t\t\t\t\t\t\t\t\t\tchunkshape=np.append([1],block_shape),\n",
    "\t\t\t\t\t\t\t\t\t\t\tfilters=filters)\n",
    "\tstorage[\"labels\"]= hdf5_file.create_earray(hdf5_file.root, \"labels\", img_dtype,  \n",
    "\t\t\t\t\t\t\t\t\t\t\tshape=[0], \n",
    "\t\t\t\t\t\t\t\t\t\t\tchunkshape=[1],\n",
    "\t\t\t\t\t\t\t\t\t\t\tfilters=filters)\n",
    "\tstorage[\"slide_ids\"]= hdf5_file.create_earray(hdf5_file.root, \"slide_ids\", img_dtype,\n",
    "\t\t\t\t\t\t\t\t\t\t\tshape=[0],\n",
    "\t\t\t\t\t\t\t\t\t\t\tchunkshape=[1],\n",
    "\t\t\t\t\t\t\t\t\t\t\tfilters=filters)\n",
    "\n",
    "\t\n",
    "\tfor filei in range(nimgs): #now for each of the files\n",
    "\t\tprint(filei)\n",
    "\t\timg=np.zeros((patch_size,patch_size))\n",
    "\t\timg = Image.fromarray(img, mode=\"RGB\")\n",
    "\t\tdraw = ImageDraw.Draw(img)\n",
    "\t\t\n",
    "\t\t#draw benign objects on the image.\n",
    "\t\tfor i in range(np.random.randint(1,high=max_benign_objects)):\n",
    "\t\t\td=np.random.randint(diameter_min,diameter_max)\n",
    "\t\t\tsqueeze_constant = np.random.randint(-d/2, d/2)\n",
    "\t\t\tul=np.random.randint(diameter_min,patch_size-diameter_max,2)\n",
    "\t\t\tpoint2=ul + d\n",
    "\t\t\tpoint2[0] = point2[0] + squeeze_constant\n",
    "\t\t\t\n",
    "\t\t\t# 3 varieties of benign objects\n",
    "\t\t\tvariety = np.random.randint(0,3)\n",
    "\t\t\tif variety == 0:  # draw blue circle\n",
    "\t\t\t\tdraw.ellipse(list(np.append(ul,ul+d)),fill=(0,0,255))\n",
    "\t\t\telif variety == 1:  # draw blue ovals\n",
    "\t\t\t\tdraw.ellipse(list(np.append(ul,point2)),fill=(0,0,255))\n",
    "\t\t\telif variety == 2:  # draw red circle\n",
    "\t\t\t\tdraw.ellipse(list(np.append(ul,ul+d)),fill=(255,0,0))\n",
    "\t\n",
    "\t\tslide_id = None\n",
    "\t\tlabel = None\n",
    "\n",
    "\t\t#fairly assign a slide-level id to each patch according to its bag\n",
    "\t\tif phase == 'train':\n",
    "\t\t\tslide_id = train_slide_ids[np.random.randint(0, num_slides[0])]\t# random slide_id\n",
    "\t\t\tif slide_id < num_slides[0]/2:\n",
    "\t\t\t\tlabel = 0\n",
    "\t\t\telse:\n",
    "\t\t\t\tlabel = 1\n",
    "\t\telif phase == 'val':\n",
    "\t\t\tslide_id = val_slide_ids[np.random.randint(0,num_slides[1])]\n",
    "\t\t\tif slide_id < num_slides[1]/2:\n",
    "\t\t\t\tlabel = 0\n",
    "\t\t\telse:\n",
    "\t\t\t\tlabel = 1\n",
    "\t\t\n",
    "\t\t\n",
    "\t\tif label:\n",
    "\t\t\tif np.random.random() <= percent_pos_per_slide:\t\t# controls the percentage of cancerous patches per slide\n",
    "\t\t\t\tfor i in range(np.random.randint(1,high=max_cancerous_objects+1)):\n",
    "\t\t\t\t\td=np.random.randint(diameter_min,diameter_max)\n",
    "\t\t\t\t\tsqueeze_constant = np.random.randint(-d/2,d/2)\n",
    "\t\t\t\t\tul=np.random.randint(diameter_min,patch_size-diameter_max,2)\n",
    "\t\t\t\t\tpoint2=ul + d\n",
    "\t\t\t\t\tpoint2[0] = point2[0] + squeeze_constant\n",
    "\t\t\t\t\tdraw.ellipse(list(np.append(ul,point2)),fill=(255,0,0))#red ellipse represents benign\n",
    "\t\t\t\ttotals[1]+=1\n",
    "\t\telse:\n",
    "\t\t\ttotals[0]+=1\n",
    "\t\t\t#add cancerous object to total\n",
    "\t\t\n",
    "\t\tdel draw\n",
    "\n",
    "\t\tstorage[\"imgs\"].append(np.array(img)[None,::])\n",
    "\t\tstorage[\"labels\"].append([np.uint8(label)])\n",
    "\t\tstorage[\"slide_ids\"].append([np.uint8(slide_id)])\n",
    "\t\t\n",
    "\t#lastly, we should store the number of pixels\n",
    "\tnpixels=hdf5_file.create_carray(hdf5_file.root, 'classsizes', tables.Atom.from_dtype(totals.dtype), totals.shape)\n",
    "\tnpixels[:]=totals\n",
    "\thdf5_file.close()\n",
    "\t\n",
    "print(\"done\")"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "4PqNjbRW0ShC",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "d3877a29-ca92-44b8-d374-506ae3f862f2",
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(totals)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visualization"
   ],
   "metadata": {
    "id": "0hX8o2Sq0kdS"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "phase=\"train\"\n",
    "db=tables.open_file(f\"./{dataname}_{phase}.pytable\")\n",
    "imgid=4998\n",
    "img = db.root.imgs[imgid,::]\n",
    "#label = torch.tensor(db.root.labels[imgid])\n",
    "label = torch.tensor(np.array(db.root.labels[imgid]))\n",
    "slide_id = torch.tensor(np.array(db.root.slide_ids[imgid]))\n",
    "#img = img[:,:,None].repeat(3,axis=2) #convert to 3 channel\n",
    "plt.imshow(img)\n",
    "print(label)\n",
    "print(slide_id)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "YQrvPfZJ0opQ",
    "outputId": "13d7113b-dd22-422c-f5d6-a7cd6730c147"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "phase=\"train\"\n",
    "db=tables.open_file(f\"./{dataname}_{phase}.pytable\")\n",
    "\n",
    "classbalance = [0,0]\n",
    "for imgid in range(0, data_size[0]):\n",
    "    label = torch.tensor(np.array(db.root.labels[imgid])).item()\n",
    "    if label:\n",
    "        classbalance[0] = classbalance[0] + 1\n",
    "    else:\n",
    "        classbalance[1] = classbalance[1] + 1\n",
    "print(classbalance)"
   ],
   "outputs": [],
   "metadata": {
    "id": "ymoj83ywnB9I"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print_bag(dataname, 'train', 64, figsize=(20,20),child_directory='')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "synthetic_data_generator",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}